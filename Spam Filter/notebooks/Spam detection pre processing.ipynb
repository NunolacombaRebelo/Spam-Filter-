{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee4f7e8f-5be0-4c94-bece-e4f1226c03c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.read_csv(\"C:/Users/nrebe/Downloads/Data Science/SMSSpamCollectiondf.csv\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"label\", \"text\"],\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "dataframe.head\n",
    "\n",
    "df_copy = dataframe.copy()\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "381e9f21-74c5-44b3-b21f-3061eb6f565b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 5572\n",
      "Rows after: 5169\n",
      "Duplicates removed: 403\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows\n",
    "df_copy = df_copy.drop_duplicates()\n",
    "df_copy.shape\n",
    "\n",
    "print(\"Rows before:\", len(dataframe))\n",
    "print(\"Rows after:\", len(df_copy))\n",
    "print(\"Duplicates removed:\", len(dataframe) - len(df_copy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "409e2369-8ac1-4902-b833-56233d8683b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>freemsg hey there darling its been weeks now a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>even my brother is not like to speak with me t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>as per your request melle melle oru minnaminun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>winner as a valued network customer you have b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>had your mobile months or more u r entitled to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>im gonna be home soon and i dont want to talk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>six chances to win cash from to pounds txt csh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>urgent you have won a week free membership in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>ive been searching for the right words to than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>i have a date on sunday with will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>xxxmobilemovieclub to use your credit click th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>oh kim watching here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "      <td>eh u remember how spell his name yes i did he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fine if thats the way u feel. Thats the way ...</td>\n",
       "      <td>fine if thats the way u feel thats the way its...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   Go until jurong point, crazy.. Available only ...   \n",
       "1                       Ok lar... Joking wif u oni...   \n",
       "2   Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   U dun say so early hor... U c already then say...   \n",
       "4   Nah I don't think he goes to usf, he lives aro...   \n",
       "5   FreeMsg Hey there darling it's been 3 week's n...   \n",
       "6   Even my brother is not like to speak with me. ...   \n",
       "7   As per your request 'Melle Melle (Oru Minnamin...   \n",
       "8   WINNER!! As a valued network customer you have...   \n",
       "9   Had your mobile 11 months or more? U R entitle...   \n",
       "10  I'm gonna be home soon and i don't want to tal...   \n",
       "11  SIX chances to win CASH! From 100 to 20,000 po...   \n",
       "12  URGENT! You have won a 1 week FREE membership ...   \n",
       "13  I've been searching for the right words to tha...   \n",
       "14                I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "15  XXXMobileMovieClub: To use your credit, click ...   \n",
       "16                         Oh k...i'm watching here:)   \n",
       "17  Eh u remember how 2 spell his name... Yes i di...   \n",
       "18  Fine if thats the way u feel. Thats the way ...   \n",
       "\n",
       "                                           clean_text  \n",
       "0   go until jurong point crazy available only in ...  \n",
       "1                             ok lar joking wif u oni  \n",
       "2   free entry in a wkly comp to win fa cup final ...  \n",
       "3         u dun say so early hor u c already then say  \n",
       "4   nah i dont think he goes to usf he lives aroun...  \n",
       "5   freemsg hey there darling its been weeks now a...  \n",
       "6   even my brother is not like to speak with me t...  \n",
       "7   as per your request melle melle oru minnaminun...  \n",
       "8   winner as a valued network customer you have b...  \n",
       "9   had your mobile months or more u r entitled to...  \n",
       "10  im gonna be home soon and i dont want to talk ...  \n",
       "11  six chances to win cash from to pounds txt csh...  \n",
       "12  urgent you have won a week free membership in ...  \n",
       "13  ive been searching for the right words to than...  \n",
       "14                  i have a date on sunday with will  \n",
       "15  xxxmobilemovieclub to use your credit click th...  \n",
       "16                               oh kim watching here  \n",
       "17  eh u remember how spell his name yes i did he ...  \n",
       "18  fine if thats the way u feel thats the way its...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def basic_cleaning(text):\n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    \n",
    "    # 3. Remove email addresses\n",
    "    text = re.sub(r\"\\S+@\\S+\\.\\S+\", \"\", text)\n",
    "\n",
    "     # 4. Remove punctuation\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    \n",
    "    # 5. Remove numbers\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    \n",
    "    # 6. Remove multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply cleaning to the dataset\n",
    "df_copy[\"clean_text\"] = df_copy[\"text\"].apply(basic_cleaning)\n",
    "\n",
    "# Preview\n",
    "df_copy[[\"text\", \"clean_text\"]].head(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8295bbb9-9425-4507-b7f8-a577f0ccfd36",
   "metadata": {},
   "source": [
    "##  **Text Preprocessing: Tokenization & Lemmatization**\n",
    "\n",
    "Before converting the SMS messages into numerical features (e.g., TF-IDF), we need to further clean and standardize the text.  \n",
    "This section introduces two essential NLP preprocessing steps: **tokenization** and **lemmatization**.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Tokenization**\n",
    "Tokenization is the process of splitting text into individual units called *tokens* (usually words).  \n",
    "This allows the model to analyze each word separately instead of treating the message as a single long string.\n",
    "\n",
    "**Example:**  \n",
    "`\"Free entry in 2 a wkly comp\"` → `[\"free\", \"entry\", \"in\", \"a\", \"wkly\", \"comp\"]`\n",
    "\n",
    "---\n",
    "\n",
    "###  **Lemmatization**\n",
    "Lemmatization reduces words to their **base dictionary form** (*lemma*).  \n",
    "This helps unify different grammatical variations of the same word, reducing vocabulary size and improving model generalization.\n",
    "\n",
    "**Example:**  \n",
    "`running → run`  \n",
    "`studies → study`  \n",
    "`better → good`\n",
    "\n",
    "---\n",
    "\n",
    "##  **Objective of This Step**\n",
    "- Convert raw SMS text into a clean and structured representation  \n",
    "- Reduce vocabulary complexity by standardizing word forms  \n",
    "- Improve the quality of TF-IDF features  \n",
    "- Increase the performance and robustness of ML models  \n",
    "\n",
    "---\n",
    "\n",
    "##  **Tools Used**\n",
    "We will use the **NLTK (Natural Language Toolkit)** library:\n",
    "- `word_tokenize` → tokenization  \n",
    "- `WordNetLemmatizer` → lemmatization  \n",
    "- `stopwords` (optional) → remove common non-informative words  \n",
    "\n",
    "NLTK is lightweight, efficient, and well-suited for preprocessing classical NLP datasets such as SMS spam detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4937530d-e3a9-44ce-8ff1-e09ce1afa5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nrebe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nrebe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\nrebe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nrebe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\nrebe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a334178-07da-4cce-a582-1d752db08575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>nah dont think go usf life around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>freemsg hey there darling its been weeks now a...</td>\n",
       "      <td>freemsg hey darling week word back id like fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>even my brother is not like to speak with me t...</td>\n",
       "      <td>even brother like speak treat like aid patent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>as per your request melle melle oru minnaminun...</td>\n",
       "      <td>per request melle melle oru minnaminunginte nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>winner as a valued network customer you have b...</td>\n",
       "      <td>winner valued network customer selected receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>had your mobile months or more u r entitled to...</td>\n",
       "      <td>mobile month u r entitled update latest colour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in a wkly comp to win fa cup final ...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "5  freemsg hey there darling its been weeks now a...   \n",
       "6  even my brother is not like to speak with me t...   \n",
       "7  as per your request melle melle oru minnaminun...   \n",
       "8  winner as a valued network customer you have b...   \n",
       "9  had your mobile months or more u r entitled to...   \n",
       "\n",
       "                                          final_text  \n",
       "0  go jurong point crazy available bugis n great ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry wkly comp win fa cup final tkts st ...  \n",
       "3                u dun say early hor u c already say  \n",
       "4           nah dont think go usf life around though  \n",
       "5  freemsg hey darling week word back id like fun...  \n",
       "6      even brother like speak treat like aid patent  \n",
       "7  per request melle melle oru minnaminunginte nu...  \n",
       "8  winner valued network customer selected receiv...  \n",
       "9  mobile month u r entitled update latest colour...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def tokenize_and_lemmatize(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Lemmatize\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    lemmas = [word for word in lemmas if word not in stop_words]\n",
    "    \n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "df_copy[\"final_text\"] = df_copy[\"clean_text\"].apply(tokenize_and_lemmatize)\n",
    "\n",
    "df_copy[[\"clean_text\", \"final_text\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52984572-c228-4fe5-8804-3980de9df681",
   "metadata": {},
   "source": [
    "**We first tokenize the text to split it into individual words, then lemmatize each word to reduce it to its base form, and finally join everything back into a clean sentence — this order is required because lemmatization can only be applied to words separately, not to a full sentence.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f6c10a3-623a-41e6-a216-d7f294a82cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.to_csv(\n",
    "    r\"C:\\Users\\nrebe\\Downloads\\Spam Filter\\preprocessed_sms_spam.csv\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d261a-9186-467e-9ccd-238f8ec6b72c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
